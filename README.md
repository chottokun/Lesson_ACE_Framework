# Agentic Context Engineering Framework Lesson ï¼ˆå­¦ç¿’ãƒ¡ãƒ¢ï¼‰:

â€»ã“ã®ãƒ¬ãƒã‚¸ãƒˆãƒªã¯å‹‰å¼·ä¸­ã®ç«‹å ´ã‹ã‚‰è‡ªåˆ†ãªã‚Šã«è§£é‡ˆãƒ»æ”¹å¤‰ã—ã¤ã¤ã¾ã¨ã‚ãŸå­¦ç¿’ãƒ­ã‚°ã§ã™ã€‚
This repository documents my learnerâ€‘level exploration of the ACE Framework.
It includes personal interpretations, experimental notes, and incremental refinements made while studying the topic.

An LLM agent framework designed to demonstrate persistent memory, structural learning, and adaptive context engineering. ACE goes beyond simple chatbots by actively learning from interactions and retrieving generalized strategies to solve novel problems.

## ğŸ§  Core Architecture

The ACE Framework operates on a cognitive cycle composed of five key components:

1.  **Curator (Retrieval & Context)**
    *   **Function**: Analyzes user intent and queries the long-term memory.
    *   **Advanced Logic**: Extracts both specific entities (e.g., "5L jug") and abstract problem classes.
    *   **MFR (Model-First Reasoning)**: Compares user input against the current **World Model (STM)** and generates **Diff Operations** (Add/Modify/Drop) to evolve the agent's understanding incrementally.

2.  **Agent (Reasoning & Action)**
    *   **Function**: The core LLM that generates responses or executes tools.
    *   **Context-Aware**: Utilizes the context provided by the Curator to ground its answers in established knowledge or past lessons.

3.  **Reflector (Queuing & Hand-off)**
    *   **Function**: Runs immediately after the agent's response.
    *   **Action**: Enqueues the interaction into a persistent `TaskQueue` (SQLite), ensuring instant feedback.

4.  **Background Worker (Structural Learning)**
    *   **Function**: A dedicated thread that continuously processes the task queue.
    *   **Structural Learning (MFR)**: Deconstructs the conversation into a **Specific Model** and **Generalization**.
    *   **Intelligent Synthesis**: Uses an **LLM-based Synthesizer** (in `BackgroundWorker`) to decide whether to **UPDATE**, **KEEP**, or add as **NEW** knowledge.
    *   **Optimization**: Shared memory/model architecture prevents redundant resource loading.

5.  **Long-Term Memory (LTM)**
    *   **Hybrid Storage**: `ACE_Memory` class combines **SQLite** (documents) and **FAISS** (vectors).
    *   **Task Queue**: `TaskQueue` class manages background jobs independently of the vector store, ensuring **ChromaDB Readiness**.

6.  **Short-Term Memory (STM)**
    *   **Function**: Maintains session-level state that persists across a single conversation.
    *   **User-Configurable**: Response style (concise, detailed, evidence-based, step-by-step, comparative, tutorial, summary-only) can be selected via UI dropdown.
    *   **Function**: Maintains session-level state that persists across a single conversation.
    *   **World Model**: Holds a structured representation of the current task (`Constraints`, `Actions`, `Entities`). This model persists across turns and evolves via MFR updates.
    *   **User-Configurable**: Response style (concise, detailed, etc.) can be selected via UI dropdown.
    *   **Context Injection**: Current time, turn count, and style instructions are injected as a `SystemMessage`.

## âš™ï¸ å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®å¯è¦–åŒ– (Visualization)

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€**åŒæœŸçš„ãªå¯¾è©±ãƒ«ãƒ¼ãƒ—**ã¨**éåŒæœŸçš„ãªå­¦ç¿’ãƒ«ãƒ¼ãƒ—**ã¨ã„ã†2ã¤ã®ä¸»è¦ãªã‚µã‚¤ã‚¯ãƒ«ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å³æ™‚å¿œç­”æ€§ã¨ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®ç¶™ç¶šçš„ãªè‡ªå·±æ”¹å–„ã‚’ä¸¡ç«‹ã•ã›ã¦ã„ã¾ã™ã€‚

```mermaid
graph TD
    %% ã‚µãƒ–ã‚°ãƒ©ãƒ•å®šç¾©ã®ä¿®æ­£: subgraph ID ["è¡¨ç¤ºå"] ã®å½¢å¼ã«å¤‰æ›´
    subgraph UI ["User Interface (app.py)"]
        User["ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼"] -->|"1. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›"| Gradio["ğŸŒ Gradio UI"]
    end

    subgraph ACE ["ACE Agent - åŒæœŸå‡¦ç† (ace_framework.py)"]
        Gradio -->|"2. ace_app.invoke() å‘¼ã³å‡ºã—"| Curator
        Curator["ğŸ§  Curator <br> æ„å›³åˆ†æãƒ»æ–‡è„ˆæ¤œç´¢"] -->|"4. é–¢é€£æƒ…å ±ã‚’æ¤œç´¢"| Memory
        Memory -->|"5. æ¤œç´¢çµæœã‚’è¿”ã™"| Curator
        Curator -->|"6. æ–‡è„ˆã‚’æ³¨å…¥"| Agent
        Agent["ğŸ¤– Agent <br> å¿œç­”ç”Ÿæˆ"] -->|"7. å¯¾è©±å†…å®¹ã‚’æ¸¡ã™"| Reflector
        Reflector["ğŸ“ Reflector <br> å¯¾è©±ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ "] -->|"8. ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«ä¿å­˜"| TaskQueue
    end

    subgraph LTM ["Long-Term Memory (ace_framework.py)"]
        Memory["ğŸ“š é•·æœŸè¨˜æ†¶ <br> (SQLite + FAISS)"]
        TaskQueue["ğŸ“¦ ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ <br> (SQLite)"]
    end

    subgraph BG ["Background Learning - éåŒæœŸå‡¦ç† (ace_framework.py)"]
        BG_Worker["âš™ï¸ Background Worker <br> å®šæœŸçš„ã«ã‚­ãƒ¥ãƒ¼ã‚’ç›£è¦–"] -->|"11. æœªå‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’å–å¾—"| TaskQueue
        TaskQueue -->|"12. ã‚¿ã‚¹ã‚¯ã‚’æ¸¡ã™"| BG_Worker
        BG_Worker -->|"13. å¯¾è©±ã‚’åˆ†æãƒ»ä¸€èˆ¬åŒ– (LLM)"| BG_Worker
        BG_Worker -->|"14. å­¦ç¿’ã—ãŸçŸ¥è­˜ã‚’ä¿å­˜"| Memory
    end

    %% Final Output to User
    Reflector -->|"9. å¿œç­”ã‚’è¿”ã™"| Gradio
    Gradio -->|"10. å¿œç­”ã‚’è¡¨ç¤º"| User

    %% Style definitions
    style User fill:#c9f,stroke:#333,stroke-width:2px
    style Gradio fill:#ccf,stroke:#333,stroke-width:2px
    style BG_Worker fill:#f96,stroke:#333,stroke-width:2px
    style Memory fill:#9cf,stroke:#333,stroke-width:2px
    style TaskQueue fill:#9cf,stroke:#333,stroke-width:2px
```

### Part 1: åŒæœŸçš„ãªå¯¾è©±ãƒ«ãƒ¼ãƒ— (ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å³æ™‚å¿œç­”)

ã“ã®ãƒ«ãƒ¼ãƒ—ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã¦ã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¿œç­”ã‚’è¿”ã™ã¾ã§ã®ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡Œã‚ã‚Œã‚‹å‡¦ç†ã§ã™ã€‚

-   **ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›**
    -   ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒGradioã®UIã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã€ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `app.py` - `gr.Textbox` / `gr.Button`

-   **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—**
    -   Gradioã®ã‚¤ãƒ™ãƒ³ãƒˆãŒ`app.py`ã®`process_chat`é–¢æ•°ã‚’ãƒˆãƒªã‚¬ãƒ¼ã—ã¾ã™ã€‚ã“ã®é–¢æ•°ã¯ã€å¯¾è©±å±¥æ­´ã‚’LangChainã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã«å¤‰æ›ã—ã€`ace_app.invoke()`ã‚’å‘¼ã³å‡ºã—ã¦ACE Agentã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `app.py` - `process_chat`é–¢æ•°

-   **Curator: æ„å›³åˆ†æã¨æ–‡è„ˆæ¤œç´¢**
    -   ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æœ€åˆã®ãƒãƒ¼ãƒ‰ã§ã‚ã‚‹`curator_node`ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚LLMã‚’å‘¼ã³å‡ºã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã€Œå…·ä½“çš„ãªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã€ã¨ã€ŒæŠ½è±¡çš„ãªå•é¡Œã‚¯ãƒ©ã‚¹ã€ã‚’æŠ½å‡ºã—ã€ãã‚Œã«åŸºã¥ã„ã¦é•·æœŸè¨˜æ†¶ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `curator_node`é–¢æ•°

-   **é•·æœŸè¨˜æ†¶ã‹ã‚‰ã®æ¤œç´¢**
    -   `curator_node`ã¯`ACE_Memory`ã‚¯ãƒ©ã‚¹ã®`search`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€FAISSã«ã‚ˆã‚‹ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨SQLite FTS5ã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€é–¢é€£ã™ã‚‹éå»ã®çŸ¥è­˜ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰ã‚’å–å¾—ã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `ACE_Memory.search`ãƒ¡ã‚½ãƒƒãƒ‰

-   **Agent: å¿œç­”ç”Ÿæˆ**
    -   Curatorã«ã‚ˆã£ã¦æ¤œç´¢ã•ã‚ŒãŸçŸ¥è­˜ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦å¯¾è©±å±¥æ­´ã®å…ˆé ­ã«æ³¨å…¥ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿½åŠ ï¼‰ã•ã‚Œã¾ã™ã€‚ã“ã®å¼·åŒ–ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã£ãŸ`agent_node`ãŒã€LLMã‚’å‘¼ã³å‡ºã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ€çµ‚çš„ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `agent_node`é–¢æ•°

-   **Reflector: å¯¾è©±ã®è¨˜éŒ²**
    -   Agentã®å¿œç­”å¾Œã€`reflector_node`ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚ã“ã®ãƒãƒ¼ãƒ‰ã®å½¹å‰²ã¯ã€ä»Šå›ã®å¯¾è©±ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¨Agentå¿œç­”ã®ãƒšã‚¢ï¼‰ã‚’åˆ†æãƒ»å­¦ç¿’ã•ã›ã‚‹ãŸã‚ã«ã€`ACE_Memory`ã®`enqueue_task`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã¦ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ï¼ˆSQLiteãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰ã«ä¿å­˜ã™ã‚‹ã“ã¨ã§ã™ã€‚ã“ã®å‡¦ç†ã¯éå¸¸ã«è»½é‡ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å¾…ãŸã›ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `reflector_node`é–¢æ•°, `ACE_Memory.enqueue_task`ãƒ¡ã‚½ãƒƒãƒ‰

-   **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å¿œç­”**
    -   `reflector_node`ã®å‡¦ç†ãŒçµ‚ã‚ã‚‹ã¨ã€åŒæœŸå‡¦ç†ã§ã‚ã‚‹`ace_app.invoke()`ãŒå®Œäº†ã—ã¾ã™ã€‚`app.py`ã®`process_chat`é–¢æ•°ã¯æœ€çµ‚çš„ãªå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’Gradioã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«è¿”ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç”»é¢ã«å¿œç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `app.py` - `process_chat`é–¢æ•°

### Part 2: éåŒæœŸçš„ãªå­¦ç¿’ãƒ«ãƒ¼ãƒ— (ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®è‡ªå·±æ”¹å–„)

ã“ã®ãƒ«ãƒ¼ãƒ—ã¯ã€ãƒ¡ã‚¤ãƒ³ã®å¯¾è©±ã‚¹ãƒ¬ãƒƒãƒ‰ã¨ã¯ç‹¬ç«‹ã—ã¦ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒéå»ã®å¯¾è©±ã‹ã‚‰å­¦ç¿’ã—ã€é•·æœŸè¨˜æ†¶ã‚’è±Šã‹ã«ã—ã¦ã„ããƒ—ãƒ­ã‚»ã‚¹ã‚’æ‹…ã„ã¾ã™ã€‚

-   **ã‚¿ã‚¹ã‚¯ã®å–å¾—**
    -   `app.py`ã®èµ·å‹•ã¨åŒæ™‚ã«é–‹å§‹ã•ã‚ŒãŸ`BackgroundWorker`ã‚¹ãƒ¬ãƒƒãƒ‰ãŒã€å®šæœŸçš„ã«ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚`ACE_Memory.fetch_pending_task`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ã„ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ'pending'ã®æœ€ã‚‚å¤ã„ã‚¿ã‚¹ã‚¯ã‚’1ä»¶å–å¾—ã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `BackgroundWorker.run`, `ACE_Memory.fetch_pending_task`

-   **åˆ†æã¨ä¸€èˆ¬åŒ–**
    -   å–å¾—ã—ãŸã‚¿ã‚¹ã‚¯ï¼ˆå¯¾è©±ãƒšã‚¢ï¼‰ã‚’`BackgroundWorker.process_task`ãƒ¡ã‚½ãƒƒãƒ‰ã§å‡¦ç†ã—ã¾ã™ã€‚ã“ã“ã§ã¯ã€ã€Œå…·ä½“çš„ãªãƒ¢ãƒ‡ãƒ«ã®åˆ†æã€ã¨ã€ŒæŠ½è±¡çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¸€èˆ¬åŒ–ã€ã‚’è¡Œã†ã‚ˆã†ã«è¨­è¨ˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ã£ã¦LLMã‚’å†åº¦å‘¼ã³å‡ºã—ã¾ã™ã€‚ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã€å¯¾è©±ã‹ã‚‰å†åˆ©ç”¨å¯èƒ½ãªçŸ¥è­˜ï¼ˆæ•™è¨“ã‚„æˆ¦ç•¥ï¼‰ãŒæŠ½å‡ºã•ã‚Œã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `BackgroundWorker.process_task`

-   **é•·æœŸè¨˜æ†¶ã¸ã®ä¿å­˜**
    -   LLMã«ã‚ˆã‚‹åˆ†æçµæœã«ã€ä¿å­˜ã™ã¹ãä¾¡å€¤ãŒã‚ã‚‹ï¼ˆ`should_store: true`ï¼‰ã¨åˆ¤æ–­ã•ã‚ŒãŸå ´åˆã€æŠ½å‡ºã•ã‚ŒãŸçŸ¥è­˜ãŒ`ACE_Memory.add`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’é€šã˜ã¦é•·æœŸè¨˜æ†¶ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯SQLiteã«ã€ãã®ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ã¯FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœªæ¥ã®å¯¾è©±ã§CuratorãŒã“ã®æ–°ã—ã„çŸ¥è­˜ã‚’æ¤œç´¢ãƒ»åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `ACE_Memory.add`ãƒ¡ã‚½ãƒƒãƒ‰

## ğŸš€ Setup & Installation

This project uses `uv` for fast and reliable dependency management.

### Prerequisites
*   Python 3.10+
*   `uv` installed (`curl -LsSf https://astral.sh/uv/install.sh | sh`)

### Installation

```bash
# 1. Clone the repository
git clone <repository_url>
cd ace_rm

# 2. Install dependencies
uv sync
```

### Environment Configuration

Create a `.env` file in the root directory (see `.env.example` for a template). All configuration is centrally managed in `src/ace_rm/config.py`.

```env
# --- LLM Settings ---
LLM_MODEL=gpt-oss-120b
LLM_API_KEY=your_api_key_here
LLM_BASE_URL=https://api.ai.sakura.ad.jp/v1/
LLM_TEMPERATURE=0.0

# --- Multi-language Settings ---
# "ja" for Japanese, "en" for English
ACE_LANG=ja

# --- Embedding Settings ---
# cl-nagoya/ruri-v3-30m is optimized for Japanese retrieval
ACE_EMBEDDING_MODEL=cl-nagoya/ruri-v3-30m
ACE_DISTANCE_METRIC=cosine
ACE_DISTANCE_THRESHOLD=0.7
ACE_DEVICE=cpu # Optional: cpu or cuda (default: auto-detection)

# --- Multi-user Settings ---
# "shared" (Default): All users interact with a single, global memory.
# "isolated": Each user session gets a private, independent memory.
LTM_MODE=shared
```

## âš¡ Optimization & Scalability

The framework has been refactored for high-performance and future-proof scalability:

-   **Batch Insertion (30x Speedup)**: Implemented `add_batch` logic. Bulk memory operations are now processed in a single transaction/FAISS update, reducing insertion time from 31ms to ~1ms per document.
-   **Resource Sharing**: Optimized `BackgroundWorker` to share a single `SentenceTransformer` instance with the Agent. This results in **50% less RAM usage** during concurrent operation.
-   **Vector DB Hardware Acceleration**: FAISS automatically utilizes GPU (CUDA) if available for indexing. The embedding model device can be explicitly set via `ACE_DEVICE` in `.env`.
-   **ChromaDB Readiness**: The modular split between `ACE_Memory` and `TaskQueue` allows swapping the vector backend to ChromaDB without affecting the background processing logic.

## ğŸ–¥ï¸ Usage

### Interactive Web UI (Gradio)

The main entry point is a 3-pane Gradio interface that visualizes the agent's internal thought process.

```bash
uv run python src/ace_rm/app.py
```

*   **Left Pane**: Chat interface.
*   **Center Pane**: Debug view showing **Curator** retrieval, **STM (World Model)** state, **LTM Status**, and **Background Processing** status.
*   **Right Pane**: Live view of the Long-Term Memory database.

#### ğŸ›ï¸ Response Style (STM Settings)

In the debug panel, you can select a response style to control how the agent formats its answers:

| Style | Description |
|:---|:---|
| **ç°¡æ½” (Concise)** | Brief, key points only |
| **è©³ç´° (Detailed)** | Comprehensive with background info |
| **æ ¹æ‹ é‡è¦– (Evidence-based)** | Cites sources and reasoning |
| **ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ— (Step-by-step)** | Ordered procedural explanation |
| **æ¯”è¼ƒãƒ»å¯¾ç…§ (Comparative)** | Pros/cons analysis |
| **ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ« (Tutorial)** | Beginner-friendly walkthrough |
| **è¦ç´„ã®ã¿ (Summary-only)** | 1-2 sentence conclusion |

### Command Line Interface

You can also interact with the core logic via provided test scripts.

## ğŸ§ª Testing & Verification

### Manual Memory Flow Test

We provide a specialized script to verify the agent's cognitive loop (Learn -> Retrieve -> Transfer). This script simulates a "Water Jug Puzzle" scenario to demonstrate structural learning.

```bash
uv run python tests/manual_test_memory_flow.py
```

**What this script does:**

1.  **Step 1 (Learning)**:
    *   Sends a query: *"How to measure 4L using 3L and 5L jugs?"*
    *   **Expectation**: The Agent solves it. The **Reflector** analyzes the solution, abstracts it into a "Water Jug / Diophantine Reachability" strategy, and stores it in memory.

2.  **Step 2 (Transfer)**:
    *   Sends a follow-up query: *"Can you apply the same strategy to 5L and 8L jugs to measure 2L?"*
    *   **Expectation**: The **Curator** retrieves the generalized strategy learned in Step 1. The Agent applies this strategy to the new variables (5L & 8L) to solve the new problem without starting from scratch.

**Output Interpretation:**
*   Look for `[Reflector] Should Store: True` in Step 1.
*   Look for `[Curator] Found knowledge about: ...` in Step 2.

### Unit Tests

Run the standard test suite to verify individual components.

```bash
uv run pytest
```

## ğŸ“‚ Project Structure

```text
ace_rm/
â”œâ”€â”€ src/ace_rm/
â”‚   â”œâ”€â”€ memory/           # Memory storage & Vector search (ACE_Memory, TaskQueue)
â”‚   â”œâ”€â”€ agent/            # LangGraph agent definitions & nodes
â”‚   â”œâ”€â”€ workers/          # Background processing (BackgroundWorker)
â”‚   â”œâ”€â”€ prompts/          # Externalized system prompts (multilingual)
â”‚   â”œâ”€â”€ utils/            # Shared utilities (Embedding model manager)
â”‚   â”œâ”€â”€ config.py         # Centralized configuration management
â”‚   â”œâ”€â”€ ace_framework.py  # Facade module (Unified interface for compatibility)
â”‚   â””â”€â”€ app.py            # Gradio UI application
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ manual_test_memory_flow.py 
â”‚   â”œâ”€â”€ benchmark_ace.py  # Performance measurement tool
â”‚   â””â”€â”€ ...
â”œâ”€â”€ user_data/            # Isolated session data (SQLite/FAISS)
â””â”€â”€ pyproject.toml
```

## References
- Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models. arXiv: [2510.04618](https://arxiv.org/abs/2510.04618)
- Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling. arXiv: [2512.14474](https://arxiv.org/abs/2512.14474)
