# Agentic Context Engineering Framework Lesson ï¼ˆå­¦ç¿’ãƒ¡ãƒ¢ï¼‰:

â€»ã“ã®ãƒ¬ãƒã‚¸ãƒˆãƒªã¯å‹‰å¼·ä¸­ã®ç«‹å ´ã‹ã‚‰è‡ªåˆ†ãªã‚Šã«è§£é‡ˆãƒ»æ”¹å¤‰ã—ã¤ã¤ã¾ã¨ã‚ãŸå­¦ç¿’ãƒ­ã‚°ã§ã™ã€‚
This repository documents my learnerâ€‘level exploration of the ACE Framework.
It includes personal interpretations, experimental notes, and incremental refinements made while studying the topic.

An LLM agent framework designed to demonstrate persistent memory, structural learning, and adaptive context engineering. ACE goes beyond simple chatbots by actively learning from interactions and retrieving generalized strategies to solve novel problems.

## ğŸ§  Core Architecture

The ACE Framework operates on a cognitive cycle composed of five key components:

1.  **Curator (Retrieval & Context)**
    *   **Function**: Analyzes user intent and queries the long-term memory.
    *   **Advanced Logic**: Extracts both specific entities (e.g., "5L jug") and abstract problem classes (e.g., "Constraint Satisfaction"). It injects relevant past experiences into the prompt context *before* the agent generates a response.

2.  **Agent (Reasoning & Action)**
    *   **Function**: The core LLM that generates responses or executes tools.
    *   **Context-Aware**: Utilizes the context provided by the Curator to ground its answers in established knowledge or past lessons.

3.  **Reflector (Queuing & Hand-off)**
    *   **Function**: Runs immediately after the agent's response.
    *   **Action**: Instead of blocking the user for analysis, it **queues** the interaction into a persistent task queue, ensuring instant feedback to the user.

4.  **Background Worker (Async Analysis)**
    *   **Function**: A dedicated thread that continuously processes the task queue.
    *   **Structural Learning (MFR)**: Performs the heavy lifting of deconstructing the conversation into a **Specific Model** and **Generalization**.
    *   **Benefits**: Achieves **High Responsiveness** (UI doesn't freeze) and **Zero Data Loss** (tasks are persisted in DB until successfully processed).

5.  **Long-Term Memory**
    *   **Hybrid Storage**: Combines **SQLite** for structured metadata/text and **FAISS** for vector embedding search.
    *   **Task Queue**: Uses a persistent SQLite table to manage background jobs, ensuring no insights are lost even across restarts.
    *   **Persistence**: Knowledge survives application restarts, allowing the agent to "grow" over time.

## âš™ï¸ å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®å¯è¦–åŒ– (Visualization)

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€**åŒæœŸçš„ãªå¯¾è©±ãƒ«ãƒ¼ãƒ—**ã¨**éåŒæœŸçš„ãªå­¦ç¿’ãƒ«ãƒ¼ãƒ—**ã¨ã„ã†2ã¤ã®ä¸»è¦ãªã‚µã‚¤ã‚¯ãƒ«ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å³æ™‚å¿œç­”æ€§ã¨ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®ç¶™ç¶šçš„ãªè‡ªå·±æ”¹å–„ã‚’ä¸¡ç«‹ã•ã›ã¦ã„ã¾ã™ã€‚

```mermaid
graph TD
    %% ã‚µãƒ–ã‚°ãƒ©ãƒ•å®šç¾©ã®ä¿®æ­£: subgraph ID ["è¡¨ç¤ºå"] ã®å½¢å¼ã«å¤‰æ›´
    subgraph UI ["User Interface (app.py)"]
        User["ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼"] -->|"1. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›"| Gradio["ğŸŒ Gradio UI"]
    end

    subgraph ACE ["ACE Agent - åŒæœŸå‡¦ç† (ace_framework.py)"]
        Gradio -->|"2. ace_app.invoke() å‘¼ã³å‡ºã—"| Curator
        Curator["ğŸ§  Curator <br> æ„å›³åˆ†æãƒ»æ–‡è„ˆæ¤œç´¢"] -->|"4. é–¢é€£æƒ…å ±ã‚’æ¤œç´¢"| Memory
        Memory -->|"5. æ¤œç´¢çµæœã‚’è¿”ã™"| Curator
        Curator -->|"6. æ–‡è„ˆã‚’æ³¨å…¥"| Agent
        Agent["ğŸ¤– Agent <br> å¿œç­”ç”Ÿæˆ"] -->|"7. å¯¾è©±å†…å®¹ã‚’æ¸¡ã™"| Reflector
        Reflector["ğŸ“ Reflector <br> å¯¾è©±ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ "] -->|"8. ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«ä¿å­˜"| TaskQueue
    end

    subgraph LTM ["Long-Term Memory (ace_framework.py)"]
        Memory["ğŸ“š é•·æœŸè¨˜æ†¶ <br> (SQLite + FAISS)"]
        TaskQueue["ğŸ“¦ ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ <br> (SQLite)"]
    end

    subgraph BG ["Background Learning - éåŒæœŸå‡¦ç† (ace_framework.py)"]
        BG_Worker["âš™ï¸ Background Worker <br> å®šæœŸçš„ã«ã‚­ãƒ¥ãƒ¼ã‚’ç›£è¦–"] -->|"11. æœªå‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’å–å¾—"| TaskQueue
        TaskQueue -->|"12. ã‚¿ã‚¹ã‚¯ã‚’æ¸¡ã™"| BG_Worker
        BG_Worker -->|"13. å¯¾è©±ã‚’åˆ†æãƒ»ä¸€èˆ¬åŒ– (LLM)"| BG_Worker
        BG_Worker -->|"14. å­¦ç¿’ã—ãŸçŸ¥è­˜ã‚’ä¿å­˜"| Memory
    end

    %% Final Output to User
    Reflector -->|"9. å¿œç­”ã‚’è¿”ã™"| Gradio
    Gradio -->|"10. å¿œç­”ã‚’è¡¨ç¤º"| User

    %% Style definitions
    style User fill:#c9f,stroke:#333,stroke-width:2px
    style Gradio fill:#ccf,stroke:#333,stroke-width:2px
    style BG_Worker fill:#f96,stroke:#333,stroke-width:2px
    style Memory fill:#9cf,stroke:#333,stroke-width:2px
    style TaskQueue fill:#9cf,stroke:#333,stroke-width:2px
```

### Part 1: åŒæœŸçš„ãªå¯¾è©±ãƒ«ãƒ¼ãƒ— (ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å³æ™‚å¿œç­”)

ã“ã®ãƒ«ãƒ¼ãƒ—ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã¦ã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¿œç­”ã‚’è¿”ã™ã¾ã§ã®ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡Œã‚ã‚Œã‚‹å‡¦ç†ã§ã™ã€‚

-   **ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›**
    -   ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒGradioã®UIã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã€ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `app.py` - `gr.Textbox` / `gr.Button`

-   **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—**
    -   Gradioã®ã‚¤ãƒ™ãƒ³ãƒˆãŒ`app.py`ã®`process_chat`é–¢æ•°ã‚’ãƒˆãƒªã‚¬ãƒ¼ã—ã¾ã™ã€‚ã“ã®é–¢æ•°ã¯ã€å¯¾è©±å±¥æ­´ã‚’LangChainã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã«å¤‰æ›ã—ã€`ace_app.invoke()`ã‚’å‘¼ã³å‡ºã—ã¦ACE Agentã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `app.py` - `process_chat`é–¢æ•°

-   **Curator: æ„å›³åˆ†æã¨æ–‡è„ˆæ¤œç´¢**
    -   ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æœ€åˆã®ãƒãƒ¼ãƒ‰ã§ã‚ã‚‹`curator_node`ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚LLMã‚’å‘¼ã³å‡ºã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã€Œå…·ä½“çš„ãªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã€ã¨ã€ŒæŠ½è±¡çš„ãªå•é¡Œã‚¯ãƒ©ã‚¹ã€ã‚’æŠ½å‡ºã—ã€ãã‚Œã«åŸºã¥ã„ã¦é•·æœŸè¨˜æ†¶ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `curator_node`é–¢æ•°

-   **é•·æœŸè¨˜æ†¶ã‹ã‚‰ã®æ¤œç´¢**
    -   `curator_node`ã¯`ACE_Memory`ã‚¯ãƒ©ã‚¹ã®`search`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€FAISSã«ã‚ˆã‚‹ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨SQLite FTS5ã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€é–¢é€£ã™ã‚‹éå»ã®çŸ¥è­˜ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰ã‚’å–å¾—ã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `ACE_Memory.search`ãƒ¡ã‚½ãƒƒãƒ‰

-   **Agent: å¿œç­”ç”Ÿæˆ**
    -   Curatorã«ã‚ˆã£ã¦æ¤œç´¢ã•ã‚ŒãŸçŸ¥è­˜ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦å¯¾è©±å±¥æ­´ã®å…ˆé ­ã«æ³¨å…¥ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿½åŠ ï¼‰ã•ã‚Œã¾ã™ã€‚ã“ã®å¼·åŒ–ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã£ãŸ`agent_node`ãŒã€LLMã‚’å‘¼ã³å‡ºã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ€çµ‚çš„ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `agent_node`é–¢æ•°

-   **Reflector: å¯¾è©±ã®è¨˜éŒ²**
    -   Agentã®å¿œç­”å¾Œã€`reflector_node`ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚ã“ã®ãƒãƒ¼ãƒ‰ã®å½¹å‰²ã¯ã€ä»Šå›ã®å¯¾è©±ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¨Agentå¿œç­”ã®ãƒšã‚¢ï¼‰ã‚’åˆ†æãƒ»å­¦ç¿’ã•ã›ã‚‹ãŸã‚ã«ã€`ACE_Memory`ã®`enqueue_task`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã¦ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ï¼ˆSQLiteãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰ã«ä¿å­˜ã™ã‚‹ã“ã¨ã§ã™ã€‚ã“ã®å‡¦ç†ã¯éå¸¸ã«è»½é‡ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å¾…ãŸã›ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `reflector_node`é–¢æ•°, `ACE_Memory.enqueue_task`ãƒ¡ã‚½ãƒƒãƒ‰

-   **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å¿œç­”**
    -   `reflector_node`ã®å‡¦ç†ãŒçµ‚ã‚ã‚‹ã¨ã€åŒæœŸå‡¦ç†ã§ã‚ã‚‹`ace_app.invoke()`ãŒå®Œäº†ã—ã¾ã™ã€‚`app.py`ã®`process_chat`é–¢æ•°ã¯æœ€çµ‚çš„ãªå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’Gradioã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«è¿”ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç”»é¢ã«å¿œç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `app.py` - `process_chat`é–¢æ•°

### Part 2: éåŒæœŸçš„ãªå­¦ç¿’ãƒ«ãƒ¼ãƒ— (ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®è‡ªå·±æ”¹å–„)

ã“ã®ãƒ«ãƒ¼ãƒ—ã¯ã€ãƒ¡ã‚¤ãƒ³ã®å¯¾è©±ã‚¹ãƒ¬ãƒƒãƒ‰ã¨ã¯ç‹¬ç«‹ã—ã¦ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒéå»ã®å¯¾è©±ã‹ã‚‰å­¦ç¿’ã—ã€é•·æœŸè¨˜æ†¶ã‚’è±Šã‹ã«ã—ã¦ã„ããƒ—ãƒ­ã‚»ã‚¹ã‚’æ‹…ã„ã¾ã™ã€‚

-   **ã‚¿ã‚¹ã‚¯ã®å–å¾—**
    -   `app.py`ã®èµ·å‹•ã¨åŒæ™‚ã«é–‹å§‹ã•ã‚ŒãŸ`BackgroundWorker`ã‚¹ãƒ¬ãƒƒãƒ‰ãŒã€å®šæœŸçš„ã«ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚`ACE_Memory.fetch_pending_task`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ã„ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ'pending'ã®æœ€ã‚‚å¤ã„ã‚¿ã‚¹ã‚¯ã‚’1ä»¶å–å¾—ã—ã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `BackgroundWorker.run`, `ACE_Memory.fetch_pending_task`

-   **åˆ†æã¨ä¸€èˆ¬åŒ–**
    -   å–å¾—ã—ãŸã‚¿ã‚¹ã‚¯ï¼ˆå¯¾è©±ãƒšã‚¢ï¼‰ã‚’`BackgroundWorker.process_task`ãƒ¡ã‚½ãƒƒãƒ‰ã§å‡¦ç†ã—ã¾ã™ã€‚ã“ã“ã§ã¯ã€ã€Œå…·ä½“çš„ãªãƒ¢ãƒ‡ãƒ«ã®åˆ†æã€ã¨ã€ŒæŠ½è±¡çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¸€èˆ¬åŒ–ã€ã‚’è¡Œã†ã‚ˆã†ã«è¨­è¨ˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ã£ã¦LLMã‚’å†åº¦å‘¼ã³å‡ºã—ã¾ã™ã€‚ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã€å¯¾è©±ã‹ã‚‰å†åˆ©ç”¨å¯èƒ½ãªçŸ¥è­˜ï¼ˆæ•™è¨“ã‚„æˆ¦ç•¥ï¼‰ãŒæŠ½å‡ºã•ã‚Œã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `BackgroundWorker.process_task`

-   **é•·æœŸè¨˜æ†¶ã¸ã®ä¿å­˜**
    -   LLMã«ã‚ˆã‚‹åˆ†æçµæœã«ã€ä¿å­˜ã™ã¹ãä¾¡å€¤ãŒã‚ã‚‹ï¼ˆ`should_store: true`ï¼‰ã¨åˆ¤æ–­ã•ã‚ŒãŸå ´åˆã€æŠ½å‡ºã•ã‚ŒãŸçŸ¥è­˜ãŒ`ACE_Memory.add`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’é€šã˜ã¦é•·æœŸè¨˜æ†¶ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯SQLiteã«ã€ãã®ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ã¯FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœªæ¥ã®å¯¾è©±ã§CuratorãŒã“ã®æ–°ã—ã„çŸ¥è­˜ã‚’æ¤œç´¢ãƒ»åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
    -   **é–¢é€£ã‚³ãƒ¼ãƒ‰**: `ace_framework.py` - `ACE_Memory.add`ãƒ¡ã‚½ãƒƒãƒ‰

## ğŸš€ Setup & Installation

This project uses `uv` for fast and reliable dependency management.

### Prerequisites
*   Python 3.10+
*   `uv` installed (`curl -LsSf https://astral.sh/uv/install.sh | sh`)

### Installation

```bash
# 1. Clone the repository
git clone <repository_url>
cd ace_rm

# 2. Install dependencies
uv sync
```

### Environment Configuration

Create a `.env` file in the root directory:

```env
# Required: Compatible OpenAI API Key (e.g., Sakura, OpenAI, Azure)
SAKURA_API_KEY=your_api_key_here

# Optional: Long-Term Memory (LTM) Mode
# Controls how the agent's memory is managed in a multi-user environment.
# - "isolated" (Default): Each user session gets a private, independent memory. This is recommended for most use cases to ensure data privacy.
# - "shared": All users interact with a single, global memory. The agent learns collectively from all interactions.
LTM_MODE=isolated
```

## ğŸ–¥ï¸ Usage

### Interactive Web UI (Gradio)

The main entry point is a 3-pane Gradio interface that visualizes the agent's internal thought process.

```bash
uv run python src/ace_rm/app.py
```

*   **Left Pane**: Chat interface.
*   **Center Pane**: Debug view showing **Curator** retrieval and **Reflector** analysis in real-time.
*   **Right Pane**: Live view of the Long-Term Memory database.

### Command Line Interface

You can also interact with the core logic via provided test scripts.

## ğŸ§ª Testing & Verification

### Manual Memory Flow Test

We provide a specialized script to verify the agent's cognitive loop (Learn -> Retrieve -> Transfer). This script simulates a "Water Jug Puzzle" scenario to demonstrate structural learning.

```bash
uv run python tests/manual_test_memory_flow.py
```

**What this script does:**

1.  **Step 1 (Learning)**:
    *   Sends a query: *"How to measure 4L using 3L and 5L jugs?"*
    *   **Expectation**: The Agent solves it. The **Reflector** analyzes the solution, abstracts it into a "Water Jug / Diophantine Reachability" strategy, and stores it in memory.

2.  **Step 2 (Transfer)**:
    *   Sends a follow-up query: *"Can you apply the same strategy to 5L and 8L jugs to measure 2L?"*
    *   **Expectation**: The **Curator** retrieves the generalized strategy learned in Step 1. The Agent applies this strategy to the new variables (5L & 8L) to solve the new problem without starting from scratch.

**Output Interpretation:**
*   Look for `[Reflector] Should Store: True` in Step 1.
*   Look for `[Curator] Found knowledge about: ...` in Step 2.

### Unit Tests

Run the standard test suite to verify individual components.

```bash
uv run pytest
```

## ğŸ“‚ Project Structure

```text
ace_rm/
â”œâ”€â”€ src/ace_rm/
â”‚   â”œâ”€â”€ ace_framework.py  # Core logic (Graph definition, Nodes, Memory)
â”‚   â””â”€â”€ app.py            # Gradio UI application
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ manual_test_memory_flow.py # End-to-end cognitive flow verification
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docs/                 # Architecture and planning documents
â”œâ”€â”€ ace_memory.db         # SQLite database (auto-generated)
â”œâ”€â”€ ace_memory.faiss      # Vector index (auto-generated)
â””â”€â”€ pyproject.toml        # Project configuration
```

## References
- Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models. arXiv: [2510.04618](https://arxiv.org/abs/2510.04618)
- Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling. arXiv: [2512.14474](https://arxiv.org/abs/2512.14474)
